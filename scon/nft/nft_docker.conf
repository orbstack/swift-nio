# special syntax:
# - scon removes #DEFAULT defines, to inject constants
# - scon removes " counter" for perf
# - we avoid proper templates, so that this is valid for quick "nft -f" testing

flush ruleset

define IF_SCON = eth0 #DEFAULT
define VNET_GATEWAY_IP4 = 0.250.250.1 #DEFAULT
define VNET_GATEWAY_IP6 = fd07:b51a:cc66:f0::1 #DEFAULT
define SCON_HOST_BRIDGE_IP4 = 198.19.249.3 #DEFAULT
define SCON_HOST_BRIDGE_IP6 = fd07:b51a:cc66:0:a617:db5e:0ab7:e9f1 #DEFAULT
define SCON_SUBNET6_CIDR = fd07:b51a:cc66:0::/64 #DEFAULT
define NAT64_SOURCE_IP4 = 10.183.233.241 #DEFAULT
define K8S_MERGED_CIDR4 = 192.168.194.0/24 #DEFAULT
define K8S_MERGED_CIDR6 = fd07:b51a:cc66:a::/64 #DEFAULT

define DOCKER_FWMARK_LOCAL_ROUTE = 0xb3c60000 #DEFAULT
define DOCKER_FWMARK_TPROXY = 0x7d8a0000 #DEFAULT
define DOCKER_FWMARK_TPROXY_OUTBOUND = 0x9f7a0000 #DEFAULT
define DOCKER_FWMARK_NFQUEUE_SKIP = 0x58ac0000 #DEFAULT
define DOCKER_FWMARK_DNAT = 0x2b9d0000 #DEFAULT

define QUEUE_DOMAINPROXY_HTTP_PROBE = 23478 #DEFAULT

# all chains have higher prio than docker/k8s iptables-nft
table inet orbstack {
    set docker_bridges {
        type ifname
    }

    set host_bridge_ports {
        type ifname
    }

    # this holds the upstreams for other docker containers' domainproxy ips
    # we need to do this dnat inside the docker machine in order to preserve source ip
    # this does not hold the upstreams for machines
    map domainproxy4 {
        type ipv4_addr : ipv4_addr
    }
    map domainproxy6 {
        type ipv6_addr : ipv6_addr
    }

    # this is a set of the domainproxy ips that have been probed for tls
    set domainproxy4_probed_tls {
        type ipv4_addr
    }
    set domainproxy6_probed_tls {
        type ipv6_addr
    }

    # this is a map of the upstreams for domainproxy ips that have been probed for http
    map domainproxy4_probed_http_upstreams {
        type ipv4_addr : ipv4_addr . inet_service
    }
    map domainproxy6_probed_http_upstreams {
        type ipv6_addr : ipv6_addr . inet_service
    }

    # since it's not possible to check if ip saddr == ip daddr, we need a set of the same ip to the same ip to check it
    # note that this is different from the masquerade set in ovm. this hold upstream ip . upstream ip so we can check if it's the same
    # that's because this happens post-dnat, whereas the ovm set is used pre-dnat
    set domainproxy4_masquerade {
        type ipv4_addr . ipv4_addr
    }
    set domainproxy6_masquerade {
        type ipv6_addr . ipv6_addr
    }

    flowtable ft {
        hook ingress priority filter
        # TODO: safe to do this for orbmirror, or does return route break?
        devices = { $IF_SCON }
    }

    chain prerouting-mangle {
        type filter hook prerouting priority mangle; policy accept;

        # asymmetrical tproxy routing:
        # we need to hijack responses to tproxy back to lo so they don't get forwarded to their spoofed source addr
        ct mark $DOCKER_FWMARK_TPROXY_OUTBOUND meta mark set $DOCKER_FWMARK_LOCAL_ROUTE
        # we also need to hijack inbound tproxy connection to localhost. unlike ovm, domainproxy ips are not anyip in the docker machine
        # so we use a route-local routing table
        ct mark $DOCKER_FWMARK_TPROXY meta mark set $DOCKER_FWMARK_LOCAL_ROUTE
    }

    chain tlsproxy {
        # hijack traffic to localhost so it can get picked up by the tproxy bpf program
        # the conntrack mark ensures subsequent packets also get properly hijacked to localhost
        # note this is only used for docker <-> docker tproxy so we can get source addr

        # accept traffic that has been probed
        # we need to hijack to localhost and mark traffic as being from domainproxy
        ip daddr @domainproxy4_probed_tls counter ct mark set $DOCKER_FWMARK_TPROXY meta mark set $DOCKER_FWMARK_LOCAL_ROUTE accept
        ip6 daddr @domainproxy6_probed_tls counter ct mark set $DOCKER_FWMARK_TPROXY meta mark set $DOCKER_FWMARK_LOCAL_ROUTE accept

        # # nfqueue: let userspace probe upstream ports to simulate conditional accept for tproxy (i.e. RST if upstream would send RST, only accept if upstream 80/443 exists)
        # # important because happy eyeballs relies on a failed v6 connection to fall back to v4
        # # no bypass: if queue overflows, make user wait for upstream probe to finish, rather than incorrectly letting them connect to the proxy
        # the verdict of this queue is always repeat with skip mark
        # if the probe succeeded, the host will be added to the probed set and thus be accepted
        # if the probe failed, this will be skipped because of mark, and the packet will be rejected
        meta mark != $DOCKER_FWMARK_NFQUEUE_SKIP counter queue num $QUEUE_DOMAINPROXY_HTTP_PROBE

        # if we got passed here, the probe failed so we should reject
        counter reject with tcp reset
    }

    chain dynamic-tlsproxy {
        # added dynamically by dockeragent
        #jump tlsproxy
    }

    chain domainproxy-http {
        # `meta l4proto tcp` is required for mapping to inet_service
        meta l4proto tcp ip daddr @domainproxy4_probed_http_upstreams counter meta mark set $DOCKER_FWMARK_DNAT dnat ip to ip daddr map @domainproxy4_probed_http_upstreams
        meta l4proto tcp ip6 daddr @domainproxy6_probed_http_upstreams counter meta mark set $DOCKER_FWMARK_DNAT dnat ip6 to ip6 daddr map @domainproxy6_probed_http_upstreams

        meta mark != $DOCKER_FWMARK_NFQUEUE_SKIP counter queue num $QUEUE_DOMAINPROXY_HTTP_PROBE

        counter reject with tcp reset
    }

    chain prerouting {
        type nat hook prerouting priority dstnat - 1; policy accept;

        # 172.17.0.1 IP gateway compat. people hard code this...
        # redirect to local IP on same interface (eth0, i.e. xxx.2 docker machine's external IP)
        # only do so if packet would otherwise go out to internet, in case user is using 172.17/16
        ip daddr 172.17.0.1 fib daddr . mark oif eq $IF_SCON counter redirect

        # dynamic tlsproxy hook
        tcp dport 443 ip daddr @domainproxy4 counter jump dynamic-tlsproxy
        tcp dport 443 ip6 daddr @domainproxy6 counter jump dynamic-tlsproxy

        # probe for http proxy and dnat to the right port
        tcp dport 80 ip daddr @domainproxy4 jump domainproxy-http
        tcp dport 80 ip6 daddr @domainproxy6 jump domainproxy-http

        # note this will only succeed if ip daddr is in @domainproxy4
        # this is only used for docker <-> docker communication. docker <-> machine communication is handled by ovm
        # we handle docker <-> docker communication in the docker machine so we can preserve source addr
        ip daddr @domainproxy4 counter meta mark set $DOCKER_FWMARK_DNAT dnat to ip daddr map @domainproxy4
        ip6 daddr @domainproxy6 counter meta mark set $DOCKER_FWMARK_DNAT dnat to ip6 daddr map @domainproxy6
    }

    chain postrouting {
        type nat hook postrouting priority srcnat - 1; policy accept;

        # "fix" ipv4 docker port forward source IP as seen by container servers:
        # normally docker only does DNAT w/o MASQUERADE to preserve source IP, but our source IP is internal vnet and people expect it to come from the machine like normal linux loopback
        # needed because people make assumptions about source IPs
        # domainproxy traffic is attributed to scon host ips
        ip saddr { $VNET_GATEWAY_IP4, $NAT64_SOURCE_IP4, $SCON_HOST_BRIDGE_IP4 } iif $IF_SCON counter masquerade
        ip6 saddr { $VNET_GATEWAY_IP6, $SCON_HOST_BRIDGE_IP6 } iif $IF_SCON counter masquerade

        # VM can only route the /64 ULA that the machine was assigned
        # masquerade other outgoing IPv6 traffic to fix kind ipv6 access
        # TODO: what was this for???
        ip6 saddr fc00::/7 ip6 saddr != $SCON_SUBNET6_CIDR oif eth0 counter masquerade

        # prevent routing loop: a packet received from macOS bridge must not be sent back to macOS
        # TODO: sometimes k8s packets still loop with this rule, so we need the failsafe in postrouting-dynamic
        iifname @host_bridge_ports oif $IF_SCON counter drop

        # if a docker container is trying to access itself, we masquerade so that we receive response packets
        # for some reason, this works fine without broute
        # blame the ghosts
        ip daddr . ip saddr @domainproxy4_masquerade counter masquerade
        ip6 daddr . ip6 saddr @domainproxy6_masquerade counter masquerade

        # added at boot if k8s is enabled
        #jump postrouting-dynamic
    }

    chain postrouting-dynamic {
        # fix k8s packets leaking to the internet if there's no kube iptables rule for a service IP
        # can happen when pods try to connect to other services before they're up
        # this is also a failsafe for routing loops between vmnet bridges and eth0
        ip daddr $K8S_MERGED_CIDR4 oif $IF_SCON counter drop
        ip6 daddr $K8S_MERGED_CIDR6 oif $IF_SCON counter drop
    }

    chain output-mangle {
        type route hook output priority mangle; policy accept;

        # this makes tlsproxy work on output
        tcp dport 443 ip daddr @domainproxy4 counter jump dynamic-tlsproxy
        tcp dport 443 ip6 daddr @domainproxy6 counter jump dynamic-tlsproxy

        # tproxy sends outbound packets with this mark via SO_MARK
        # this is so we know to hijack response packets to lo
        meta mark $DOCKER_FWMARK_TPROXY_OUTBOUND counter ct mark set $DOCKER_FWMARK_TPROXY_OUTBOUND
    }

    chain output-dstnat {
        type nat hook output priority dstnat; policy accept;

        # skip if tlsproxy is trying to hijack to localhost
        meta mark $DOCKER_FWMARK_LOCAL_ROUTE accept

        # this makes domainproxy-http work on output
        tcp dport 80 ip daddr @domainproxy4 jump domainproxy-http
        tcp dport 80 ip6 daddr @domainproxy6 jump domainproxy-http

        # resolve domainproxy ips
        dnat to ip daddr map @domainproxy4
        dnat to ip6 daddr map @domainproxy6
    }

    chain early-forward {
        type filter hook forward priority filter - 1; policy accept;

        # fastpath for forwarding and NAT: skip most of net stack after first reply packet
        meta l4proto { tcp, udp } meta oifkind != "bridge" flow add @ft counter
    }
}

table bridge orbstack_bridge {
    chain prerouting {
        type filter hook prerouting priority -199; policy accept;

        # we need to set broute for tproxy_outbound because the bridge will forward return traffic back to the spoofed source addr without it
        # this happens before it can get hijacked to localhost
        ct mark $DOCKER_FWMARK_TPROXY_OUTBOUND counter meta broute set 1 meta pkttype set host accept
    }
}
