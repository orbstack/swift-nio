# special syntax:
# - scon removes #DEFAULT defines, to inject constants
# - scon removes " counter" for perf
# - we avoid proper templates, so that this is valid for quick "nft -f" testing

flush ruleset

define IF_SCON = eth0 #DEFAULT
define VNET_GATEWAY_IP4 = 0.250.250.1 #DEFAULT
define VNET_GATEWAY_IP6 = fd07:b51a:cc66:f0::1 #DEFAULT
define SCON_HOST_BRIDGE_IP4 = 198.19.249.3 #DEFAULT
define SCON_HOST_BRIDGE_IP6 = fd07:b51a:cc66:0:a617:db5e:0ab7:e9f1 #DEFAULT
define SCON_SUBNET6_CIDR = fd07:b51a:cc66:0::/64 #DEFAULT
define NAT64_SOURCE_IP4 = 10.183.233.241 #DEFAULT
define K8S_MERGED_CIDR4 = 192.168.194.0/24 #DEFAULT
define K8S_MERGED_CIDR6 = fd07:b51a:cc66:a::/64 #DEFAULT

define DOCKER_FWMARK_LOCAL_ROUTE = 0xb3c60000 #DEFAULT
define DOCKER_FWMARK_TPROXY = 0x7d8a0000 #DEFAULT
define DOCKER_FWMARK_TPROXY_OUTBOUND = 0x9f7a0000 #DEFAULT
define DOCKER_FWMARK_NFQUEUE_REJECT = 0xbf7a0000 #DEFAULT

define QUEUE_DOMAINPROXY_PENDING = 23478 #DEFAULT

# all chains have higher prio than docker/k8s iptables-nft
table inet orbstack {
    set docker_bridges {
        type ifname
    }

    set host_bridge_ports {
        type ifname
    }

    # this holds the upstreams for other docker containers' domainproxy ips
    # we need to do this dnat inside the docker machine in order to preserve source ip
    # this does not hold the upstreams for machines
    map domainproxy4 {
        type ipv4_addr : ipv4_addr
    }
    set domainproxy4_pending {
        type ipv4_addr
    }

    map domainproxy6 {
        type ipv6_addr : ipv6_addr
    }
    set domainproxy6_pending {
        type ipv6_addr
    }

    # since it's not possible to check if ip saddr == ip daddr, we need a set of the same ip to the same ip to check it
    # note that this is different from the masquerade set in ovm. this hold upstream ip . upstream ip so we can check if it's the same
    # that's because this happens post-dnat, whereas the ovm set is used pre-dnat
    set domainproxy4_masquerade {
        type ipv4_addr . ipv4_addr
    }
    set domainproxy6_masquerade {
        type ipv6_addr . ipv6_addr
    }

    flowtable ft {
        hook ingress priority filter
        # TODO: safe to do this for orbmirror, or does return route break?
        devices = { $IF_SCON }
    }

    chain prerouting-mangle {
        type filter hook prerouting priority mangle; policy accept;

        # asymmetrical tproxy routing:
        # we need to hijack responses to tproxy back to lo so they don't get forwarded to their spoofed source addr
        ct mark $DOCKER_FWMARK_TPROXY_OUTBOUND meta mark set $DOCKER_FWMARK_LOCAL_ROUTE
        # we also need to hijack inbound tproxy connection to localhost. unlike ovm, domainproxy ips are not anyip in the docker machine
        # so we use a route-local routing table
        ct mark $DOCKER_FWMARK_TPROXY meta mark set $DOCKER_FWMARK_LOCAL_ROUTE
    }

    chain prerouting-tlsproxy {
        # hijack traffic to localhost so it can get picked up by the tproxy bpf program
        # the conntrack mark ensures subsequent packets also get properly hijacked to localhost
        # note this is only used for docker <-> docker tproxy so we can get source addr

        # reject traffic that needs to be rejected by nfqueue
        # traffic gets back here because we set verdict to repeat
        meta mark $DOCKER_FWMARK_NFQUEUE_REJECT counter reject with tcp reset

        # nfqueue: let userspace probe upstream ports to simulate conditional accept for tproxy (i.e. RST if upstream would send RST, only accept if upstream 80/443 exists)
        # important because happy eyeballs relies on a failed v6 connection to fall back to v4
        # no bypass: if queue overflows, make user wait for upstream probe to finish, rather than incorrectly letting them connect to the proxy
        ip daddr @domainproxy4_pending counter ct mark set $DOCKER_FWMARK_TPROXY meta mark set $DOCKER_FWMARK_LOCAL_ROUTE queue num $QUEUE_DOMAINPROXY_PENDING
        ip6 daddr @domainproxy6_pending counter ct mark set $DOCKER_FWMARK_TPROXY meta mark set $DOCKER_FWMARK_LOCAL_ROUTE queue num $QUEUE_DOMAINPROXY_PENDING

        ip daddr @domainproxy4 counter ct mark set $DOCKER_FWMARK_TPROXY meta mark set $DOCKER_FWMARK_LOCAL_ROUTE accept
        ip6 daddr @domainproxy6 counter ct mark set $DOCKER_FWMARK_TPROXY meta mark set $DOCKER_FWMARK_LOCAL_ROUTE accept
    }

    chain prerouting-dynamic-tlsproxy {
        # added dynamically by dockeragent
        #jump prerouting-tlsproxy
    }

    chain prerouting {
        type nat hook prerouting priority dstnat - 1; policy accept;

        # 172.17.0.1 IP gateway compat. people hard code this...
        # redirect to local IP on same interface (eth0, i.e. 198.19.249.2 docker machine's external IP)
        # only do so if packet would otherwise go out to internet, in case user is using 172.17/16
        ip daddr 172.17.0.1 fib daddr . mark oif eq $IF_SCON counter redirect

        # dynamic tlsproxy hook
        tcp dport 443 jump prerouting-dynamic-tlsproxy

        # note this will only succeed if ip daddr is in @domainproxy4
        # this is only used for docker <-> docker communication. docker <-> machine communication is handled by ovm
        # we handle docker <-> docker communication in the docker machine so we can preserve source addr
        dnat to ip daddr map @domainproxy4
        dnat to ip6 daddr map @domainproxy6
    }

    chain postrouting {
        type nat hook postrouting priority srcnat - 1; policy accept;

        # "fix" ipv4 docker port forward source IP as seen by container servers:
        # normally docker only does DNAT w/o MASQUERADE to preserve source IP, but our source IP is internal vnet and people expect it to come from the machine like normal linux loopback
        # needed because people make assumptions about source IPs
        # domainproxy traffic is attributed to scon host ips
        ip saddr { $VNET_GATEWAY_IP4, $NAT64_SOURCE_IP4, $SCON_HOST_BRIDGE_IP4 } iif $IF_SCON counter masquerade
        ip6 saddr { $VNET_GATEWAY_IP6, $SCON_HOST_BRIDGE_IP6 } iif $IF_SCON counter masquerade

        # VM can only route the /64 ULA that the machine was assigned
        # masquerade other outgoing IPv6 traffic to fix kind ipv6 access
        # TODO: what was this for???
        ip6 saddr fc00::/7 ip6 saddr != $SCON_SUBNET6_CIDR oif eth0 counter masquerade

        # prevent routing loop: a packet received from macOS bridge must not be sent back to macOS
        # TODO: sometimes k8s packets still loop with this rule, so we need the failsafe in postrouting-dynamic
        iifname @host_bridge_ports oif $IF_SCON counter drop

        # if a docker container is trying to access itself, we masquerade so that we receive response packets
        # for some reason, this works fine without broute
        # blame the ghosts
        ip daddr . ip saddr @domainproxy4_masquerade counter masquerade
        ip6 daddr . ip6 saddr @domainproxy6_masquerade counter masquerade

        # added at boot if k8s is enabled
        #jump postrouting-dynamic
    }

    chain postrouting-dynamic {
        # fix k8s packets leaking to the internet if there's no kube iptables rule for a service IP
        # can happen when pods try to connect to other services before they're up
        # this is also a failsafe for routing loops between vmnet bridges and eth0
        ip daddr $K8S_MERGED_CIDR4 oif $IF_SCON counter drop
        ip6 daddr $K8S_MERGED_CIDR6 oif $IF_SCON counter drop
    }

    chain output-mangle {
        type route hook output priority mangle; policy accept;

        # tproxy sends outbound packets with this mark via SO_MARK
        # this is so we know to hijack response packets to lo
        meta mark $DOCKER_FWMARK_TPROXY_OUTBOUND counter ct mark set $DOCKER_FWMARK_TPROXY_OUTBOUND
    }

    chain early-forward {
        type filter hook forward priority filter - 1; policy accept;

        # fastpath for forwarding and NAT: skip most of net stack after first reply packet
        meta l4proto { tcp, udp } meta oifkind != "bridge" flow add @ft counter
    }
}

table bridge orbstack_bridge {
    chain prerouting {
        type filter hook prerouting priority -199; policy accept;

        # we need to set broute for tproxy_outbound because the bridge will forward return traffic back to the spoofed source addr without it
        # this happens before it can get hijacked to localhost
        ct mark $DOCKER_FWMARK_TPROXY_OUTBOUND counter meta broute set 1 meta pkttype set host accept
    }
}
